import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError
import time # DÃ¹ng cho viá»‡c mÃ´ phá»ng Ä‘á»™ trá»…/backoff náº¿u cáº§n

# --- Cáº¥u hÃ¬nh Trang Streamlit ---
st.set_page_config(
    page_title="App PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh",
    layout="wide"
)

st.title("á»¨ng dá»¥ng PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh ğŸ“Š")

# ************************* KHá»I Táº O SESSION STATE VÃ€ CHAT HISTORY *************************
if "chat_history" not in st.session_state:
    # Lá»‹ch sá»­ chat: [{"role": "user", "parts": [{"text": "..."}]}, ...]
    st.session_state["chat_history"] = []
if "data_context" not in st.session_state:
    # Dá»¯ liá»‡u tÃ i chÃ­nh Ä‘Ã£ xá»­ lÃ½ (dÆ°á»›i dáº¡ng markdown string) Ä‘á»ƒ cung cáº¥p context cho AI
    st.session_state["data_context"] = ""
# ******************************************************************************************


# --- HÃ m tÃ­nh toÃ¡n chÃ­nh (Sá»­ dá»¥ng Caching Ä‘á»ƒ Tá»‘i Æ°u hiá»‡u suáº¥t) ---
@st.cache_data
def process_financial_data(df):
    """Thá»±c hiá»‡n cÃ¡c phÃ©p tÃ­nh TÄƒng trÆ°á»Ÿng vÃ  Tá»· trá»ng."""

    # Äáº£m báº£o cÃ¡c giÃ¡ trá»‹ lÃ  sá»‘ Ä‘á»ƒ tÃ­nh toÃ¡n
    numeric_cols = ['NÄƒm trÆ°á»›c', 'NÄƒm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 1. TÃ­nh Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng
    # DÃ¹ng .replace(0, 1e-9) cho Series Pandas Ä‘á»ƒ trÃ¡nh lá»—i chia cho 0
    df['Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)'] = (
        (df['NÄƒm sau'] - df['NÄƒm trÆ°á»›c']) / df['NÄƒm trÆ°á»›c'].replace(0, 1e-9)
    ) * 100

    # 2. TÃ­nh Tá»· trá»ng theo Tá»•ng TÃ i sáº£n
    # Lá»c chá»‰ tiÃªu "Tá»”NG Cá»˜NG TÃ€I Sáº¢N"
    tong_tai_san_row = df[df['Chá»‰ tiÃªu'].str.contains('Tá»”NG Cá»˜NG TÃ€I Sáº¢N', case=False, na=False)]

    if tong_tai_san_row.empty:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y chá»‰ tiÃªu 'Tá»”NG Cá»˜NG TÃ€I Sáº¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NÄƒm trÆ°á»›c'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NÄƒm sau'].iloc[0]

    # Xá»­ lÃ½ giÃ¡ trá»‹ 0 thá»§ cÃ´ng cho máº«u sá»‘ Ä‘á»ƒ tÃ­nh tá»· trá»ng
    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    # TÃ­nh tá»· trá»ng vá»›i máº«u sá»‘ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
    df['Tá»· trá»ng NÄƒm trÆ°á»›c (%)'] = (df['NÄƒm trÆ°á»›c'] / divisor_N_1) * 100
    df['Tá»· trá»ng NÄƒm sau (%)'] = (df['NÄƒm sau'] / divisor_N) * 100

    return df

# --- HÃ m gá»i API Gemini cho Nháº­n xÃ©t Tá»± Ä‘á»™ng (Chá»©c nÄƒng 5) ---
def get_ai_analysis(data_for_ai, api_key):
    """Gá»­i dá»¯ liá»‡u phÃ¢n tÃ­ch Ä‘áº¿n Gemini API vÃ  nháº­n nháº­n xÃ©t tá»± Ä‘á»™ng."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash'

        prompt = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch tÃ i chÃ­nh chuyÃªn nghiá»‡p. Dá»±a trÃªn cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh sau, hÃ£y Ä‘Æ°a ra má»™t nháº­n xÃ©t khÃ¡ch quan, ngáº¯n gá»n (khoáº£ng 3-4 Ä‘oáº¡n) vá» tÃ¬nh hÃ¬nh tÃ i chÃ­nh cá»§a doanh nghiá»‡p. ÄÃ¡nh giÃ¡ táº­p trung vÃ o tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng, thay Ä‘á»•i cÆ¡ cáº¥u tÃ i sáº£n vÃ  kháº£ nÄƒng thanh toÃ¡n hiá»‡n hÃ nh.

        Dá»¯ liá»‡u thÃ´ vÃ  chá»‰ sá»‘:
        {data_for_ai}
        """

        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text

    except APIError as e:
        return f"Lá»—i gá»i Gemini API: Vui lÃ²ng kiá»ƒm tra KhÃ³a API hoáº·c giá»›i háº¡n sá»­ dá»¥ng. Chi tiáº¿t lá»—i: {e}"
    except Exception as e:
        return f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"


# --- HÃ m xá»­ lÃ½ khung chat tÆ°Æ¡ng tÃ¡c (Chá»©c nÄƒng 6) ---
def handle_chat_query(user_prompt, api_key, data_context):
    """Xá»­ lÃ½ yÃªu cáº§u chat, duy trÃ¬ ngá»¯ cáº£nh dá»¯ liá»‡u vÃ  lá»‹ch sá»­ chat."""
    
    try:
        client = genai.Client(api_key=api_key)
    except Exception as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o Gemini Client: {e}")
        return "KhÃ´ng thá»ƒ khá»Ÿi táº¡o Gemini Client."

    model_name = 'gemini-2.5-flash'

    # XÃ¢y dá»±ng System Instruction (HÆ°á»›ng dáº«n cho AI)
    system_instruction = f"""
    Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch tÃ i chÃ­nh thÃ´ng minh vÃ  nhiá»‡t tÃ¬nh.
    Ngá»¯ cáº£nh Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ cá»§a doanh nghiá»‡p (bao gá»“m Chá»‰ tiÃªu, NÄƒm trÆ°á»›c, NÄƒm sau, Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng vÃ  Tá»· trá»ng cÆ¡ cáº¥u) Ä‘Æ°á»£c cung cáº¥p trong dáº¥u ngoáº·c kÃ©p 3 láº§n:
    \"\"\"
    {data_context}
    \"\"\"
    Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chÃ­nh xÃ¡c, dá»±a trÃªn dá»¯ liá»‡u báº¡n Ä‘Æ°á»£c cung cáº¥p.
    Báº¡n PHáº¢I tham kháº£o dá»¯ liá»‡u nÃ y khi tráº£ lá»i. Náº¿u dá»¯ liá»‡u khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³.
    """
    
    # 1. Chuáº©n bá»‹ contents (bao gá»“m System Instruction vÃ  lá»‹ch sá»­ chat)
    
    # ThÃªm System Instruction lÃ m hÆ°á»›ng dáº«n Ä‘áº§u tiÃªn (sá»­ dá»¥ng role 'user' Ä‘á»ƒ thiáº¿t láº­p ngá»¯ cáº£nh áº©n)
    contents = [
        {"role": "user", "parts": [{"text": system_instruction}]}
    ]
    
    # ThÃªm toÃ n bá»™ lá»‹ch sá»­ chat hiá»‡n táº¡i (lÆ°u Ã½: lá»‹ch sá»­ chat trong session_state CHá»ˆ chá»©a user/model xen káº½)
    contents.extend(st.session_state["chat_history"])
    
    # ThÃªm prompt hiá»‡n táº¡i cá»§a user vÃ o contents
    contents.append({"role": "user", "parts": [{"text": user_prompt}]})
    
    # Cáº­p nháº­t lá»‹ch sá»­ chat hiá»ƒn thá»‹ (chá»‰ thÃªm tin nháº¯n user má»›i nháº¥t)
    st.session_state["chat_history"].append({"role": "user", "parts": [{"text": user_prompt}]})


    # 2. Gá»­i yÃªu cáº§u tá»›i Gemini
    try:
        response = client.models.generate_content(
            model=model_name,
            contents=contents
        )
        ai_response = response.text
        
        # 3. Cáº­p nháº­t lá»‹ch sá»­ chat vá»›i cÃ¢u tráº£ lá»i cá»§a AI
        st.session_state["chat_history"].append({"role": "model", "parts": [{"text": ai_response}]})
        return ai_response

    except APIError as e:
        return f"Lá»—i gá»i Gemini API (Chat): Vui lÃ²ng kiá»ƒm tra KhÃ³a API hoáº·c giá»›i háº¡n sá»­ dá»¥ng. Chi tiáº¿t lá»—i: {e}"
    except Exception as e:
        return f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong chat: {e}"


# --- Chá»©c nÄƒng 1: Táº£i File ---
uploaded_file = st.file_uploader(
    "1. Táº£i file Excel BÃ¡o cÃ¡o TÃ i chÃ­nh (Chá»‰ tiÃªu | NÄƒm trÆ°á»›c | NÄƒm sau)",
    type=['xlsx', 'xls']
)

if uploaded_file is not None:
    try:
        df_raw = pd.read_excel(uploaded_file)

        # Tiá»n xá»­ lÃ½: Äáº£m báº£o chá»‰ cÃ³ 3 cá»™t quan trá»ng
        df_raw.columns = ['Chá»‰ tiÃªu', 'NÄƒm trÆ°á»›c', 'NÄƒm sau']

        # Xá»­ lÃ½ dá»¯ liá»‡u
        df_processed = process_financial_data(df_raw.copy())

        if df_processed is not None:
            # ******************************* Cáº¬P NHáº¬T DATA CONTEXT CHO CHAT *******************************
            st.session_state["data_context"] = df_processed.to_markdown(index=False)
            # **********************************************************************************************

            # --- Chá»©c nÄƒng 2 & 3: Hiá»ƒn thá»‹ Káº¿t quáº£ ---
            st.subheader("2. Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng & 3. Tá»· trá»ng CÆ¡ cáº¥u TÃ i sáº£n")
            st.dataframe(df_processed.style.format({
                'NÄƒm trÆ°á»›c': '{:,.0f}',
                'NÄƒm sau': '{:,.0f}',
                'Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)': '{:.2f}%',
                'Tá»· trá»ng NÄƒm trÆ°á»›c (%)': '{:.2f}%',
                'Tá»· trá»ng NÄƒm sau (%)': '{:.2f}%'
            }), use_container_width=True)

            # --- Chá»©c nÄƒng 4: TÃ­nh Chá»‰ sá»‘ TÃ i chÃ­nh ---
            st.subheader("4. CÃ¡c Chá»‰ sá»‘ TÃ i chÃ­nh CÆ¡ báº£n")

            try:
                # Láº¥y TÃ i sáº£n ngáº¯n háº¡n
                tsnh_n = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]
                tsnh_n_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]

                # Láº¥y Ná»£ ngáº¯n háº¡n
                no_ngan_han_N = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]
                no_ngan_han_N_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]

                # TÃ­nh toÃ¡n
                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1

                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        label="Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm trÆ°á»›c)",
                        value=f"{thanh_toan_hien_hanh_N_1:.2f} láº§n"
                    )
                with col2:
                    st.metric(
                        label="Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm sau)",
                        value=f"{thanh_toan_hien_hanh_N:.2f} láº§n",
                        delta=f"{thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1:.2f}"
                    )

            except IndexError:
                st.warning("Thiáº¿u chá»‰ tiÃªu 'TÃ€I Sáº¢N NGáº®N Háº N' hoáº·c 'Ná»¢ NGáº®N Háº N' Ä‘á»ƒ tÃ­nh chá»‰ sá»‘.")
                thanh_toan_hien_hanh_N = "N/A" # DÃ¹ng Ä‘á»ƒ trÃ¡nh lá»—i á»Ÿ Chá»©c nÄƒng 5
                thanh_toan_hien_hanh_N_1 = "N/A"

            # --- Chá»©c nÄƒng 5: Nháº­n xÃ©t AI (Tá»± Ä‘á»™ng) ---
            st.subheader("5. Nháº­n xÃ©t TÃ¬nh hÃ¬nh TÃ i chÃ­nh (AI)")

            # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ gá»­i cho AI (TÆ°Æ¡ng tá»± code gá»‘c)
            data_for_ai = pd.DataFrame({
                'Chá»‰ tiÃªu': [
                    'ToÃ n bá»™ Báº£ng phÃ¢n tÃ­ch (dá»¯ liá»‡u thÃ´)',
                    'TÄƒng trÆ°á»Ÿng TÃ i sáº£n ngáº¯n háº¡n (%)',
                    'Thanh toÃ¡n hiá»‡n hÃ nh (N-1)',
                    'Thanh toÃ¡n hiá»‡n hÃ nh (N)'
                ],
                'GiÃ¡ trá»‹': [
                    df_processed.to_markdown(index=False),
                    (f"{df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)'].iloc[0]:.2f}%" if not df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)].empty else 'N/A'),
                    f"{thanh_toan_hien_hanh_N_1}",
                    f"{thanh_toan_hien_hanh_N}"
                ]
            }).to_markdown(index=False)

            if st.button("YÃªu cáº§u AI PhÃ¢n tÃ­ch"):
                api_key = st.secrets.get("GEMINI_API_KEY")

                if api_key:
                    with st.spinner('Äang gá»­i dá»¯ liá»‡u vÃ  chá» Gemini phÃ¢n tÃ­ch...'):
                        ai_result = get_ai_analysis(data_for_ai, api_key)
                        st.markdown("**Káº¿t quáº£ PhÃ¢n tÃ­ch tá»« Gemini AI:**")
                        st.info(ai_result)
                else:
                    st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y KhÃ³a API. Vui lÃ²ng cáº¥u hÃ¬nh KhÃ³a 'GEMINI_API_KEY' trong Streamlit Secrets.")

    except ValueError as ve:
        st.error(f"Lá»—i cáº¥u trÃºc dá»¯ liá»‡u: {ve}")
    except Exception as e:
        st.error(f"CÃ³ lá»—i xáº£y ra khi Ä‘á»c hoáº·c xá»­ lÃ½ file: {e}. Vui lÃ²ng kiá»ƒm tra Ä‘á»‹nh dáº¡ng file.")

else:
    st.info("Vui lÃ²ng táº£i lÃªn file Excel Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¢n tÃ­ch.")

# ************************* CHá»¨C NÄ‚NG Má»šI: KHUNG CHAT Há»I ÄÃP *************************

st.markdown("---") # ÄÆ°á»ng káº» ngang Ä‘á»ƒ phÃ¢n biá»‡t
st.subheader("6. Chat Há»i Ä‘Ã¡p ChuyÃªn sÃ¢u (Gemini)")

if st.session_state["data_context"]:
    # 1. Hiá»ƒn thá»‹ Lá»‹ch sá»­ Chat
    for message in st.session_state["chat_history"]:
        # Äáº£m báº£o chá»‰ hiá»ƒn thá»‹ tin nháº¯n cÃ³ text (trÃ¡nh hiá»ƒn thá»‹ system instruction áº©n)
        if message["role"] != "system":
            with st.chat_message(message["role"]):
                st.markdown(message["parts"][0]["text"])

    # 2. Xá»­ lÃ½ Input tá»« ngÆ°á»i dÃ¹ng
    user_prompt = st.chat_input("Há»i Gemini báº¥t ká»³ cÃ¢u há»i nÃ o vá» BÃ¡o cÃ¡o TÃ i chÃ­nh Ä‘Ã£ táº£i lÃªn (vÃ­ dá»¥: 'TÃ i sáº£n ngáº¯n háº¡n tÄƒng trÆ°á»Ÿng bao nhiÃªu pháº§n trÄƒm?').")

    if user_prompt:
        # Láº¥y API Key
        api_key = st.secrets.get("GEMINI_API_KEY")

        if not api_key:
            st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y KhÃ³a API 'GEMINI_API_KEY'. KhÃ´ng thá»ƒ báº¯t Ä‘áº§u Chat.")
        else:
            # Hiá»ƒn thá»‹ prompt cá»§a user ngay láº­p tá»©c
            # Viá»‡c nÃ y Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n trong hÃ m handle_chat_query, nÃªn ta chá»‰ cáº§n gá»i hÃ m
            
            with st.spinner("Gemini Ä‘ang phÃ¢n tÃ­ch vÃ  tráº£ lá»i..."):
                # Gá»i hÃ m chat, hÃ m nÃ y sáº½ tá»± Ä‘á»™ng cáº­p nháº­t session_state vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
                handle_chat_query(user_prompt, api_key, st.session_state["data_context"])
                # Streamlit sáº½ tá»± Ä‘á»™ng rerun vÃ  hiá»ƒn thá»‹ tin nháº¯n má»›i nháº¥t
            st.rerun()
    
else:
    st.warning("Vui lÃ²ng táº£i lÃªn vÃ  xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh (BÆ°á»›c 1) trÆ°á»›c khi báº¯t Ä‘áº§u khung chat.")

# *************************************************************************************
